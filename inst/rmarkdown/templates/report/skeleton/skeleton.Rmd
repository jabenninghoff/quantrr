---
title: "TEMPLATE Risk Analysis Report"
author: ""
date: '2025-00-00'
date-modified: '2025-00-00'
categories: []
order:
format:
  html:
    code-fold: true
    code-tools: true
    # TODO: code-link not working in this report
    # code-link: true
output:
  html_notebook:
    theme:
      version: 5
      preset: bootstrap
    pandoc_args: --shift-heading-level-by=1
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
---

One sentence description of the risk analysis.

```{r setup, message = FALSE, warning = FALSE}
library(quantrr)
library(readxl)
library(janitor)
library(validate)
library(dplyr)
library(formattable)
library(purrr)
library(ggplot2)
library(jbplot)
library(plotly)

# TODO: workaround for https://github.com/r-lib/lintr/issues/2790, update when
#   https://github.com/data-cleaning/validate/pull/197 is released (1.1.6+)
is.nzchar <- nzchar # nolint: object_name_linter.

# set the relative file path and name to import
report_file <- "data/file.xlsx"
```

# Environment Statement

Add environment statement here (1-2 paragraphs).

# Import

Import and validate data from Excel.

Add explanation of how the data was collected here.

```{r import}
risks <- read_xlsx(report_file, sheet = "Risks") |>
  clean_names()

validate_risks <- local({
  validate_rules <- validator(
    risk_char = is.character(risk),
    risk_not_na = !is.na(risk),
    risk_not_blank = is.nzchar(risk, keep_na = TRUE),
    desc_char = is.character(description),
    desc_not_na = !is.na(description),
    desc_not_blank = is.nzchar(risk, keep_na = TRUE)
  )
  confront(risks, validate_rules)
})

check_validation(validate_risks, sheet = "Risks")

estimates <- read_xlsx(report_file, sheet = "Estimates") |>
  clean_names() |>
  rename(
    lambda = frequency_per_yer, p05 = low_5_percent, p95 = high_95_percent, p50 = most_likely
  )

validate_estimates <- local({
  validate_rules <- validator(
    risk_not_na = !is.na(risk),
    risk_match = risk %in% risks$risk,
    expert_char = is.character(expert),
    expert_not_na = !is.na(expert),
    expert_not_blank = is.nzchar(expert, keep_na = TRUE),
    lambda_num = is.numeric(lambda),
    lambda_pos = lambda > 0,
    p05_num = is.numeric(p05),
    p05_pos = p05 > 0,
    p95_num = is.numeric(p95),
    p95_pos = p95 > 0,
    p50_num = is.numeric(p50),
    p50_pos = p50 > 0
  )
  confront(estimates, validate_rules)
})

check_validation(validate_estimates, sheet = "Estimates")
```

# Risks

Risk descriptions:

```{r risks}
formattable(risks, align = "l")
```

# Forecast

Forecast risk using Monte Carlo simulation. The average events, losses, 'typical' losses (geometric
mean), and percentage of years with no losses for each risk are summarized below:

```{r forecast}
consensus <- estimates |>
  group_by(risk) |>
  summarize(across(lambda:p50, ~ mean(.x, na.rm = TRUE)))

consensus_params <- consensus |>
  mutate(as_tibble(lnorm_param(.data$p05, .data$p95, .data$p50)))

forecast <- consensus_params |>
  select(c("risk", "lambda", "meanlog", "sdlog")) |>
  pmap(calc_risk) |>
  list_rbind()

forecast |>
  group_by(risk) |>
  mutate(no_losses = events == 0) |>
  summarize(
    avg_events = mean(events), avg_losses = mean(losses), typ_losses = gmean(losses),
    no_losses = mean(no_losses)
  ) |>
  mutate(
    across(avg_losses:typ_losses, ~ currency(.x, digits = 0L)),
    no_losses = percent(no_losses)
  ) |>
  formattable(align = "l")
```

# Losses

Losses by risk separately and in aggregate:

```{r risk_hist}
forecast |>
  # remove zero losses to plot using log10 scale
  filter(losses > 0) |>
  ggplot(aes(losses)) +
  facet_grid(vars(risk)) +
  geom_hist_bw(bins = 100) +
  scale_x_log10(labels = scales::label_currency(scale_cut = scales::cut_short_scale())) +
  labs(x = NULL, y = NULL, title = "Losses by Risk") +
  theme_quo()

forecast |>
  filter(losses > 0) |>
  ggplot(aes(losses, fill = risk)) +
  geom_histogram(bins = 100) +
  scale_x_log10(labels = scales::label_currency(scale_cut = scales::cut_short_scale())) +
  labs(x = NULL, y = NULL, fill = "Risk", title = "Total Losses") +
  scale_fill_viridis_d() +
  theme_quo()
```

# Loss Exceedance Curves

Plot loss exceedance curves for all risks and combined risk.

## By Risk

Plot loss exceedance curves for each risk:

```{r risk_le}
risk_le <- forecast |>
  group_by(risk) |>
  mutate(probability = 1 - percent_rank(losses)) |>
  filter(losses > 0) |>
  ggplot(aes(losses, probability)) +
  facet_grid(vars(risk)) +
  geom_line() +
  scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1)) +
  scale_x_log10(labels = scales::label_currency(scale_cut = scales::cut_short_scale())) +
  labs(x = NULL, y = NULL, title = "Loss Exceedance by Risk")

risk_le +
  theme_quo()
```

Interactive plot:

```{r risk_le_plotly}
ggplotly(risk_le + theme_minimal())
```

## Combined Risk

Plot loss exceedance curve for combined risk:

```{r combined_le}
combined_le <- forecast |>
  group_by(year) |>
  summarize(total_losses = sum(losses)) |>
  mutate(probability = 1 - percent_rank(total_losses)) |>
  filter(total_losses > 0) |>
  ggplot(aes(total_losses, probability)) +
  geom_line() +
  scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1)) +
  scale_x_log10(labels = scales::label_currency(scale_cut = scales::cut_short_scale())) +
  labs(x = NULL, y = NULL, title = "Combined Loss Exceedance")

combined_le +
  theme_quo()
```

Interactive plot:

```{r combined_le_plotly}
ggplotly(combined_le + theme_minimal())
```

# Appendix

Additional details on the risk quantification analysis.

## Validation

Data validation results for Risks tab:

```{r validate_risks}
plot(validate_risks)
```

Data validation results for Estimates tab:

```{r validate_estimates}
plot(validate_estimates)
```

## Estimates

All risk estimates:

```{r estimates}
estimates |>
  mutate(across(p05:p50, ~ currency(.x, digits = 0L))) |>
  formattable(align = "l")
```

## Consensus Estimate

Using a simple average of all experts that provided an estimate (not blank/NA), this gives us a
consensus estimate for the three risks of:

```{r consensus}
consensus |>
  mutate(across(p05:p50, ~ currency(.x, digits = 0L))) |>
  formattable(align = "l")
```

The consensus estimates for p05 and p95 result in the following parameters for log-normal loss
magnitude. The p50 estimate is used to calculate the percentage difference from the actual median
(`mdiff`), a measure of estimate accuracy:

```{r consensus_params}
consensus_params |>
  mutate(across(p05:p50, ~ currency(.x, digits = 0L)), mdiff = percent(mdiff)) |>
  formattable(align = "l")
```

## Forecast Summary

A `summary()` of the forecast results.

```{r summary}
summary(forecast)
```
